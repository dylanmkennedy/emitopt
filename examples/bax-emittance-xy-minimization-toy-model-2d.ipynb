{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ac8fe9",
   "metadata": {},
   "source": [
    "# Emittance minimization using Xopt with BAXGenerator running algorithm ScipyMinimizeEmittance\n",
    "In this notebook we demonstrate the use of Xopt to perform Bayesian Algorithm Execution (BAX) as a means of minimizing the emittance described by a simple optical beam size model. BAX is a generalization of Bayesian Optimization that seeks to acquire observations that provide our model with maximal information about our property of interest. In this example, our property of interest is the minimal emittance and its location in tuning-parameter-space. See https://arxiv.org/pdf/2209.04587.pdf for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2666c7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2005f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Dylan\\\\SLAC') #parent directory containing emitopt module\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "\n",
    "from emitopt.beam_dynamics import compute_emit_bmag\n",
    "from emitopt.sampling import draw_product_kernel_post_paths\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d378d",
   "metadata": {},
   "source": [
    "# Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9d65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "if False:\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    use_cuda = True\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f6014",
   "metadata": {},
   "source": [
    "# Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9323010",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2 #number of input dimensions\n",
    "noise = False #whether to add noise to the ground-truth beam size function outputs\n",
    "meas_dim = 1 #input dimension for measurement parameter\n",
    "n_obs_init = 5 #number of random initial observations for GP model\n",
    "n_samples = 10 #number of posterior samples for BAX\n",
    "n_iter = 20 #number of optimization steps for Xopt to take (after acquiring random initial data)\n",
    "rand_seed = 2\n",
    "\n",
    "#random seeds for reproducibility \n",
    "torch.manual_seed(rand_seed)\n",
    "np.random.seed(rand_seed) #only affects initial random observations through Xopt\n",
    "random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87785524",
   "metadata": {},
   "source": [
    "# Build test function from single-quadrupole optical beam size model \n",
    "Here we define a simple ground-truth beam size function for our optimization problem, where we attempt to find the location in tuning parameter space with minimal emittance. Note that the function \"test_func\" used to evaluate the ground-truth beam size function takes a dictionary as input and returns a dictionary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468de1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemittance.emittance_calc import EmitCalc\n",
    "from pyemittance.load_json_configs import load_configs\n",
    "from pyemittance.simulation import BeamSim\n",
    "\n",
    "CONFIG = load_configs('LCLS2_OTR0H04')\n",
    "CONFIG['beamline_info']\n",
    "\n",
    "q_len = CONFIG['beamline_info']['Lquad']\n",
    "rmat_x = torch.tensor(CONFIG['beamline_info']['rMatx']).reshape(2,2)\n",
    "rmat_y = torch.tensor(CONFIG['beamline_info']['rMaty']).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c052d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUNCH_PARAMS0 = {\n",
    "    'total_charge': 50e-12,\n",
    "    'norm_emit_x': 1e-6,\n",
    "    'norm_emit_y': 2e-6,\n",
    "    'beta_x': 10,\n",
    "    'alpha_x': -1,\n",
    "    'beta_y': 11,\n",
    "    'alpha_y': -2,\n",
    "    'energy': 80e6,\n",
    "    'species':'electron'\n",
    "}\n",
    "sim = BeamSim(bunch_params=BUNCH_PARAMS0, beamline_info=CONFIG['beamline_info'])\n",
    "\n",
    "\n",
    "# define variables functions\n",
    "var_names = ['x' + str(i) for i in range(ndim)]\n",
    "meas_param = var_names[meas_dim]\n",
    "\n",
    "def measure_beamsize(input_dict):\n",
    "    x_tuning = torch.tensor([])\n",
    "    for key in input_dict.keys():\n",
    "        if key is not meas_param:\n",
    "            x_tuning = torch.cat((x_tuning, torch.tensor([input_dict[key]])))\n",
    "    rms_beamsizes0 = np.array(sim.beam_size_meas(input_dict[meas_param]))\n",
    "    detuning_scale = 1. + x_tuning.abs().sum().cpu()\n",
    "    xrms, yrms = detuning_scale * rms_beamsizes0\n",
    "    return {'xrms_sq': float(xrms)**2.*1.e6,\n",
    "            'yrms_sq': float(yrms)**2.*1.e6} # mean-square beam sizes in mm squared\n",
    "\n",
    "def ground_truth_geometric_mean_emittance(emit_min, x_tuning):\n",
    "    detuning_scale = 1. + x_tuning.abs().sum(dim=1)\n",
    "    emit = emit_min * detuning_scale**2\n",
    "    return emit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e9fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.56516435, 0.01566167]),\n",
       " array([0.10047318, 0.29068046]),\n",
       " array([0.01594597, 1.41311281])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.array(sim.beam_size_meas(v))**2*1.e6 for v in np.linspace(-2,2,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73bcfe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # define test functions\n",
    "# var_names = ['x' + str(i) for i in range(ndim)]\n",
    "# meas_param = var_names[meas_dim]\n",
    "\n",
    "# beam_energy = 0.135\n",
    "# distance = torch.tensor(2.26).double()\n",
    "# q_len = torch.tensor(0.108).double()\n",
    "# s11 = torch.tensor(3e-6).double()\n",
    "# s12 = torch.tensor(1.5e-6).double()\n",
    "# s22 = torch.tensor(2e-6).double()\n",
    "# gt_min_emit = torch.sqrt(s11 * s22 - s12 ** 2)*1e6\n",
    "# print('Ground-Truth Minimum Emittance:', gt_min_emit.item())\n",
    "\n",
    "\n",
    "\n",
    "# def beam_size_squared(k, d, l, s11, s12, s22):\n",
    "#     return (\n",
    "#         (1.0 + k * d * l) ** 2 * s11 + 2.0 * (1.0 + d * l * k) * d * s12 + d ** 2 * s22\n",
    "#     )\n",
    "    \n",
    "# def toy_beam_size_squared_nd(x, meas_dim, noise=noise):\n",
    "    \n",
    "#     tuning_dims = list(range(x.shape[-1]))\n",
    "#     tuning_dims.remove(meas_dim)\n",
    "#     emit = torch.sqrt(s11 * s22 - s12 ** 2)\n",
    "#     bss = ((1 + torch.sum(x[:,tuning_dims]**2, dim=1) )* beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)).reshape(-1,1) \n",
    "# #     bss = ( (1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(x[:,tuning_dims]**2, dim=1))) ) ) * \n",
    "# #            beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)\n",
    "# #           ).reshape(-1,1) \n",
    "#     bss *= 1.e6\n",
    "#     if noise:\n",
    "#         bss *= (1 + 0.05*torch.rand_like(bss))      \n",
    "#     return bss\n",
    "\n",
    "# def toy_emit_nd(X_tuning):\n",
    "# #     return ( 1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(X_tuning**2, dim=1))) ) ) * gt_min_emit\n",
    "#     return (1 + torch.sum(X_tuning**2, dim=1) ) * gt_min_emit\n",
    "\n",
    "# def test_func(input_dict):\n",
    "#     x = torch.tensor(input_dict[meas_param]).reshape(-1,1)\n",
    "#     for key in input_dict.keys():\n",
    "#         if key is not meas_param:\n",
    "#             x = torch.cat((x, torch.tensor(input_dict[key]).reshape(-1,1)), dim=1)\n",
    "#     return {'x': float(toy_beam_size_squared_nd(x, 0).squeeze().cpu().numpy()),\n",
    "#             'y': float(toy_beam_size_squared_nd(x, 0).squeeze().cpu().numpy()),\n",
    "#            'emittance': float(toy_emit_nd(x[:,1:]).squeeze().cpu().numpy())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2c09a",
   "metadata": {},
   "source": [
    "# Construct vocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfbf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_names = ['x0', 'x1']\n",
      "meas_param = 'x1'\n",
      "domain =\n",
      " [[-2.  2.]\n",
      " [-3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "variables = {var_name: [-2,2] for var_name in var_names}\n",
    "variables[meas_param] = [-3,3] #overwrite bounds for measurement parameter to capture minimum of single-quadrupole optical model\n",
    "\n",
    "#construct vocs\n",
    "vocs = VOCS(\n",
    "    variables = variables,\n",
    "    observables = ['xrms_sq', 'yrms_sq']\n",
    ")\n",
    "\n",
    "print('variable_names =', vocs.variable_names)\n",
    "print('meas_param =', \"'\" + meas_param + \"'\")\n",
    "print('domain =\\n', vocs.bounds.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4651f47",
   "metadata": {},
   "source": [
    "# Prepare generator options.\n",
    "In this example, we use a specialty covariance module (Matern x Quadratic kernel) for our beam size model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02894212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import MaternKernel, PolynomialKernel, ScaleKernel\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "# prepare custom covariance module\n",
    "tuning_dims = list(range(vocs.n_variables))\n",
    "tuning_dims.remove(meas_dim)\n",
    "covar_module_x = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "\n",
    "scaled_covar_module_x = ScaleKernel(covar_module_x)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "covar_module_y = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "scaled_covar_module_y =  ScaleKernel(covar_module_y)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "\n",
    "# prepare options for Xopt generator\n",
    "covar_module_dict = {'xrms_sq': scaled_covar_module_x,\n",
    "                     'yrms_sq': scaled_covar_module_y}\n",
    "\n",
    "model_constructor = StandardModelConstructor(covar_modules=covar_module_dict, use_low_noise_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.numerical_optimizer import LBFGSOptimizer\n",
    "numerical_optimizer = LBFGSOptimizer(\n",
    "                                    n_raw_samples=20,\n",
    "                                    n_restarts=10,\n",
    "                                    max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd586df8",
   "metadata": {},
   "source": [
    "# Construct generator, evaluator, Xopt objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7623bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying model name='standard' use_low_noise_prior=True covar_modules={'xrms_sq': ScaleKernel(\n",
      "  (base_kernel): ProductKernel(\n",
      "    (kernels): ModuleList(\n",
      "      (0): MaternKernel(\n",
      "        (raw_lengthscale_constraint): Positive()\n",
      "      )\n",
      "      (1): PolynomialKernel(\n",
      "        (raw_offset_constraint): Positive()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), 'yrms_sq': ScaleKernel(\n",
      "  (base_kernel): ProductKernel(\n",
      "    (kernels): ModuleList(\n",
      "      (0): MaternKernel(\n",
      "        (raw_lengthscale_constraint): Positive()\n",
      "      )\n",
      "      (1): PolynomialKernel(\n",
      "        (raw_offset_constraint): Positive()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      ")} mean_modules={} trainable_mean_keys=[]\n"
     ]
    }
   ],
   "source": [
    "#Prepare Algorithm\n",
    "from emitopt.beam_dynamics import get_quad_scale_factor\n",
    "scale_factor = get_quad_scale_factor(E=.08, q_len=q_len)\n",
    "# scale_factor = 1.\n",
    "algo_kwargs = {\n",
    "        'x_key': 'xrms_sq',\n",
    "        'y_key': 'yrms_sq',\n",
    "        'scale_factor': scale_factor,\n",
    "        'q_len': q_len,\n",
    "        'rmat_x': rmat_x,\n",
    "        'rmat_y': rmat_y,\n",
    "        'n_samples': n_samples,\n",
    "        'meas_dim': meas_dim,\n",
    "        'n_steps_measurement_param': 11,\n",
    "#         'scipy_options': None,\n",
    "}\n",
    "algo = ScipyMinimizeEmittanceXY(**algo_kwargs)\n",
    "\n",
    "#construct BAX generator\n",
    "generator = BaxGenerator(vocs=vocs, \n",
    "                         gp_constructor=model_constructor, \n",
    "                         numerical_optimizer=numerical_optimizer,\n",
    "                         algorithm=algo, \n",
    "                         use_cuda=use_cuda)\n",
    "\n",
    "#construct evaluator\n",
    "evaluator = Evaluator(function=measure_beamsize)\n",
    "\n",
    "#construct Xopt optimizer\n",
    "optimizer = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae84fc5",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3553f6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>xrms_sq</th>\n",
       "      <th>yrms_sq</th>\n",
       "      <th>xopt_runtime</th>\n",
       "      <th>xopt_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256020</td>\n",
       "      <td>1.017991</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>1.185247</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.896295</td>\n",
       "      <td>1.772108</td>\n",
       "      <td>0.062580</td>\n",
       "      <td>10.401808</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.198650</td>\n",
       "      <td>-0.715626</td>\n",
       "      <td>0.317929</td>\n",
       "      <td>0.142012</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258710</td>\n",
       "      <td>1.202072</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>1.360661</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.318529</td>\n",
       "      <td>1.399036</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>1.707620</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1   xrms_sq    yrms_sq  xopt_runtime  xopt_error\n",
       "0  0.256020  1.017991  0.019058   1.185247      0.000879       False\n",
       "1  1.896295  1.772108  0.062580  10.401808      0.000218       False\n",
       "2 -0.198650 -0.715626  0.317929   0.142012      0.000181       False\n",
       "3  0.258710  1.202072  0.009921   1.360661      0.000175       False\n",
       "4  0.318529  1.399036  0.005928   1.707620      0.000172       False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call X.random_evaluate() to generate random initial points and evaluate on test_func\n",
    "optimizer.random_evaluate(n_obs_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bf85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(optimizer.data[vocs.variable_names].iloc[-2].to_numpy().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af84ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# beam_size_models = {}\n",
    "\n",
    "# #get initial emittance prediction at ground truth optimum\n",
    "# model = optimizer.generator.train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a54961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 / 20\n",
      "Scipy failed to find at least 3 physically valid solutions.\n",
      "This iteration took: 1.9732017517089844 seconds.\n",
      "\n",
      "Iteration: 2 / 20\n",
      "Scipy failed to find at least 3 physically valid solutions.\n",
      "This iteration took: 1.932201862335205 seconds.\n",
      "\n",
      "Iteration: 3 / 20\n",
      "This iteration took: 1.6202077865600586 seconds.\n",
      "\n",
      "Iteration: 4 / 20\n",
      "This iteration took: 1.6018977165222168 seconds.\n",
      "\n",
      "Iteration: 5 / 20\n",
      "This iteration took: 1.6249608993530273 seconds.\n",
      "\n",
      "Iteration: 6 / 20\n",
      "This iteration took: 1.4748287200927734 seconds.\n",
      "\n",
      "Iteration: 7 / 20\n",
      "This iteration took: 1.833125352859497 seconds.\n",
      "\n",
      "Iteration: 8 / 20\n",
      "This iteration took: 1.5265040397644043 seconds.\n",
      "\n",
      "Iteration: 9 / 20\n",
      "This iteration took: 1.5138828754425049 seconds.\n",
      "\n",
      "Iteration: 10 / 20\n",
      "This iteration took: 1.7078049182891846 seconds.\n",
      "\n",
      "Iteration: 11 / 20\n",
      "This iteration took: 1.9954819679260254 seconds.\n",
      "\n",
      "Iteration: 12 / 20\n",
      "This iteration took: 1.877394199371338 seconds.\n",
      "\n",
      "Iteration: 13 / 20\n",
      "This iteration took: 1.8664281368255615 seconds.\n",
      "\n",
      "Iteration: 14 / 20\n"
     ]
    }
   ],
   "source": [
    "# plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "# plt.xlabel('Predicted Optimal Emittance')\n",
    "# plt.ylabel('Probability Density')\n",
    "# plt.show()\n",
    "# print('sample validity rate:', svr)\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "\n",
    "    print('Iteration:', i, '/', n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # call X.step() to generate a random initial point and evaluate on test_func\n",
    "    optimizer.step()    \n",
    "\n",
    "    \n",
    "    #extract GP models\n",
    "    model = optimizer.generator.train_model()\n",
    "    bax_model_ids = [optimizer.generator.vocs.output_names.index(name)\n",
    "                            for name in optimizer.generator.algorithm.model_names_ordered]\n",
    "    bax_model = model.subset_output(bax_model_ids)\n",
    "    beam_size_model_x = bax_model.models[0]\n",
    "    beam_size_model_y = bax_model.models[1]\n",
    "    \n",
    "    #extract and store algorithm results for this iteration\n",
    "    results[i] = optimizer.generator.algorithm_results\n",
    "#     beam_size_models[i] = beam_size_model\n",
    "    \n",
    "    #get mean-predicted optimal tuning config and eval predicted emits at this location in tuning parameter space\n",
    "    algo = optimizer.generator.algorithm\n",
    "#     X_tuned, emits_at_target_valid, svr = algo.mean_output(beam_size_model,\n",
    "#                                                          torch.tensor(vocs.bounds),\n",
    "#                                                          num_restarts=10)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('This iteration took:', end-start, 'seconds.\\n')\n",
    "\n",
    "#     if i % 5 == 0:\n",
    "#         plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "#         plt.xlabel('Predicted Optimal Emittance')\n",
    "#         plt.ylabel('Probability Density')\n",
    "#         plt.show()\n",
    "#         print('sample validity rate:', svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d344f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "end = time.time()\n",
    "print('get_acquisition took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim.optimize import optimize_acqf\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    res = optimize_acqf(acq_function=acq,\n",
    "                        bounds=torch.tensor(vocs.bounds),\n",
    "                        q=1,\n",
    "                        num_restarts=10,\n",
    "                        raw_samples=20,\n",
    "                        options={'maxiter':50}\n",
    "                       )\n",
    "end = time.time()\n",
    "print('optimize_acqf took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3181749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "\n",
    "# last_acq = np.vstack(data_all[0].iloc[-1][list(vocs.variable_data([vocs.random_inputs()], '').keys())].values[:]).astype(float)\n",
    "# last_acq = torch.tensor(last_acq).reshape(1,-1)\n",
    "\n",
    "last_acq = res[0]\n",
    "# last_acq = torch.tensor(optimizer.data[vocs.variable_names].iloc[-1].to_numpy().reshape(1,-1))\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim)\n",
    "    \n",
    "fig.set_size_inches(3*(ndim), 3)\n",
    "\n",
    "for scan_dim in range(ndim):\n",
    "    X_scan = last_acq.repeat(100,1)\n",
    "#     ls = torch.linspace(*vocs.bounds.T[scan_dim],100)\n",
    "    ls = torch.linspace(last_acq[0,scan_dim]-1,last_acq[0,scan_dim]+1,100)\n",
    "\n",
    "    X_scan[:,scan_dim] = ls\n",
    "\n",
    "    acq_scan = torch.tensor([acq(X.reshape(1,-1)) for X in X_scan]).reshape(-1)\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "    ax.plot(ls.cpu(), acq_scan.detach().cpu())\n",
    "    ax.axvline(last_acq[0,scan_dim].cpu(), c='r', label='Acquisition Result')\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel('Input ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('Acquisition Function')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_sample_optima_convergence_inputs\n",
    "plot_sample_optima_convergence_inputs(results, show_valid_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c512cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_sample_optima_convergence_emits\n",
    "plot_sample_optima_convergence_emits(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_valid_emit_prediction_at_x_tuning\n",
    "\n",
    "x_tuned = torch.mean(results[n_iter]['x_stars_all'], dim=0, keepdim=True)\n",
    "print('x_tuned =', x_tuned)\n",
    "plot_valid_emit_prediction_at_x_tuning(beam_size_model_x, \n",
    "                                       x_tuned, \n",
    "                                       scale_factor = algo_kwargs['scale_factor'],\n",
    "                                       q_len = algo_kwargs['q_len'],\n",
    "                                       distance = algo_kwargs['distance'],\n",
    "                                       bounds = vocs.bounds,\n",
    "                                       meas_dim = algo_kwargs['meas_dim'],\n",
    "                                       n_samples = 10000,\n",
    "                                       n_steps_quad_scan = 10\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a01f5",
   "metadata": {},
   "source": [
    "# Plot some beam size surface samples from our current model and do a scan of the predicted emittance as a function of our single tuning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d25716",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ndim==2:\n",
    "    \n",
    "    device = torch.tensor(1).device\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, subplot_kw={\"projection\": \"3d\"})\n",
    "    fig.set_size_inches(15,10)\n",
    "\n",
    "    ax = axs[0]\n",
    "\n",
    "    for s in range(3):\n",
    "\n",
    "        # plot first 3 beam size surface samples\n",
    "        xlin, ylin = torch.arange(-3,1,0.05), torch.arange(-40,40, 1.)\n",
    "        X, Y = torch.meshgrid(xlin, ylin)\n",
    "        XY = torch.cat((X.reshape(-1,1), Y.reshape(-1,1)), dim=1)\n",
    "        print(XY.shape)\n",
    "        Z = optimizer.generator.algorithm_results['post_paths_cpu'](XY)[s].reshape(X.shape).detach()\n",
    "        cmap='viridis'\n",
    "        surf = ax.plot_surface(Y, X, Z, cmap=cmap,\n",
    "                               linewidth=0, antialiased=True, alpha=0.3, rasterized=True)\n",
    "\n",
    "        # add orange parabolic highlights\n",
    "        ax.plot(Y[0,:].numpy(), Z[0,:].numpy(), zs=X[0,0].item(), zdir='y', c='C1', lw=2, zorder=10)\n",
    "        ax.plot(Y[int(len(Z[0,:])/2),:].numpy(), Z[int(len(Z[0,:])/2),:].numpy(), zs=X[int(len(Z[0,:])/2),0].item(), zdir='y', c='C1', lw=2)\n",
    "        ax.plot(Y[-1,:].numpy(), Z[-1,:].numpy(), zs=X[-1,0].item(), zdir='y', c='C1', lw=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot initial observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[:n_obs_init]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[:n_obs_init]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[:n_obs_init]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C0', alpha=1, s=80, label='Random (Initial) Observations', zorder=15)\n",
    "\n",
    "    # plot bax observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[n_obs_init:]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[n_obs_init:]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[n_obs_init:]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C1', alpha=1, s=80, label='BAX Observations', zorder=15)\n",
    "\n",
    "    ax.set_title('Beam Size Surface Samples')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Measurement Parameter')\n",
    "    ax.set_zlabel('Beam Size Squared')\n",
    "\n",
    "    ax.set_ylim(-3, 1)\n",
    "    ax.set_zlim(0)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        torch.set_default_tensor_type(\"torch.cuda.DoubleTensor\")\n",
    "        \n",
    "   \n",
    "\n",
    "    # do a scan (along the tuning dimension) of our emittance predictions\n",
    "    emit_lowers = torch.tensor([])\n",
    "    emit_uppers = torch.tensor([])\n",
    "    emit_meds = torch.tensor([])\n",
    "    for tuning_param in xlin:\n",
    "        x_tuning = tuning_param.reshape(1,-1).to(device)\n",
    "        emits, svr = get_valid_emittance_samples(beam_size_model, \n",
    "                                                 scale_factor, \n",
    "                                                 0.108, \n",
    "                                                 2.26, \n",
    "                                                 x_tuning, \n",
    "                                                 vocs.bounds.T, \n",
    "                                                 meas_dim, \n",
    "                                                 n_samples=100000, \n",
    "                                                 n_steps_quad_scan=10)\n",
    "        emit_lower = torch.quantile(emits, q=0.025, dim=0)\n",
    "        emit_upper = torch.quantile(emits, q=0.975, dim=0)\n",
    "        emit_med = torch.quantile(emits, q=0.5, dim=0)\n",
    "\n",
    "        emit_lowers = torch.cat((emit_lowers, emit_lower))\n",
    "        emit_uppers = torch.cat((emit_uppers, emit_upper))\n",
    "        emit_meds = torch.cat((emit_meds, emit_med))\n",
    "\n",
    "    #get a few batches of n_samples pathwise sample optima\n",
    "    x_stars_all = torch.tensor([])\n",
    "    emit_stars_all = torch.tensor([])\n",
    "    for i in range(5):\n",
    "        algo = optimizer.generator.algorithm\n",
    "        results_dict = algo.get_execution_paths(beam_size_model, torch.tensor(vocs.bounds))[-1]\n",
    "        x_stars = results_dict['x_stars']\n",
    "        emit_stars = results_dict['emit_stars'].detach()\n",
    "        x_stars_all = torch.cat((x_stars_all, x_stars), dim=0)\n",
    "        emit_stars_all = torch.cat((emit_stars_all, emit_stars), dim=0)\n",
    "    \n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    ax = axs[1]\n",
    "    \n",
    "    # plot median emittance curve\n",
    "    medline, = ax.plot(emit_meds.cpu().numpy(), xlin.numpy(), zs=0, zdir='z', c='g', label='Median')\n",
    "    \n",
    "    opt_cross = ax.scatter(emit_stars_all.flatten().cpu(), x_stars_all.flatten().cpu(), zs=0, zdir='z', marker='x', s=40, c='m', alpha=0.5, label='Sample Optima')\n",
    "    \n",
    "    # plot emittance 95% confidence interval as a Poly3DCollection (ordering of vertices matters)\n",
    "    verts = (\n",
    "        [(emit_lowers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))] + \n",
    "        [(emit_uppers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))][::-1]\n",
    "    )\n",
    "    ax.add_collection3d(Poly3DCollection([verts],color='g', edgecolor='None', alpha=0.5)) # Add a polygon instead of fill_between\n",
    "\n",
    "    \n",
    "    ax.set_xlabel('Emittance')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_title('Emittance Measurement Samples')\n",
    "    \n",
    "    ax.set_xlim(0,25)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "\n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    orange_patch = mpatches.Patch(color='g', alpha=0.5, label='95% C.I.')\n",
    "    ax.legend(handles=[medline, orange_patch, opt_cross])\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    ax = axs[2]\n",
    "    bins = 10\n",
    "    freq, edges = torch.histogram(x_stars_all.flatten().cpu(), bins=bins, density=True)\n",
    "    for i in range(bins):\n",
    "        uverts = []\n",
    "        lverts = []\n",
    "        uverts += [(freq[i].item(), edges[i].item(), 0), (freq[i].item(), edges[i+1].item(), 0)]\n",
    "        lverts += [(0, edges[i+1].item(), 0), (0, edges[i].item(), 0)]\n",
    "        verts = uverts + lverts\n",
    "        ax.add_collection3d(Poly3DCollection([verts],color='m', edgecolor='k')) # Add a polygon instead of fill_between\n",
    "\n",
    "    ax.set_title('Distribution of Sample Optimal Tuning Parameters')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Frequency')\n",
    "    \n",
    "    ax.set_xlim(0,2)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "    \n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    \n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    \n",
    "    ax.dist = 12\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('beamsize-surfaces-with-emittance-1.svg', format='svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7907f",
   "metadata": {},
   "source": [
    "# Minimize sample emittance functions produced by current GP beam size model and inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select sample result\n",
    "\n",
    "sid = 5 #sample index to examine\n",
    "\n",
    "# X_tuned = X_sample_opt[sid].reshape(1,-1)\n",
    "X_tuned = optimizer.generator.algorithm_results['x_tuning_best']\n",
    "# X_tuned = torch.zeros(1,ndim-1)\n",
    "print('X_tuned =', X_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a841546",
   "metadata": {},
   "source": [
    "# Sample geometric mean of emittance x&y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.linspace(1,5,5).reshape(1,-1)\n",
    "valid = torch.tensor([[True, False, False, True, False]])\n",
    "k[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import plot_pathwise_sample_emittance_minimization_results\n",
    "\n",
    "plot_pathwise_sample_emittance_minimization_results(optimizer, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23224da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.plot_utils import post_path_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emit_sq_x = post_path_emit_squared_thick_quad(optimizer.generator.algorithm_results['post_paths_cpu_xy'][0], \n",
    "                              1*optimizer.generator.algorithm.scale_factor, \n",
    "                              optimizer.generator.algorithm.q_len, \n",
    "                              optimizer.generator.algorithm.distance, \n",
    "                              X_tuning_scan.cpu(), meas_dim, X_meas.cpu(), samplewise=False)[0]\n",
    "    emit_sq_y = post_path_emit_squared_thick_quad(optimizer.generator.algorithm_results['post_paths_cpu_xy'][1], \n",
    "                              -1*optimizer.generator.algorithm.scale_factor, \n",
    "                              optimizer.generator.algorithm.q_len, \n",
    "                              optimizer.generator.algorithm.distance, \n",
    "                              X_tuning_scan.cpu(), meas_dim, X_meas.cpu(), samplewise=False)[0]\n",
    "    geo_mean_emit = torch.sqrt(emit_sq_x.abs().sqrt() * emit_sq_y.abs().sqrt())\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    ax.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "#     ax.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    ax.plot(ls.cpu(), geo_mean_emit[sid].detach().cpu()*1.e-6, label='Sample ' + str(sid))\n",
    "    ax.axvline(X_tuned[0,scan_dim].cpu(), c='r', label='Sample optimization result')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af9764",
   "metadata": {},
   "source": [
    "# Plot posterior mean model of geometric mean emttance x&y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b195f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import post_mean_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emit_sq_x = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_x,\n",
    "        scale_factor=1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]\n",
    "    emit_sq_y = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_y,\n",
    "        scale_factor=-1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]    \n",
    "    geo_mean_emit = torch.sqrt(emit_sq_x.abs().sqrt() * emit_sq_y.abs().sqrt())\n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "\n",
    "#     ax.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    ax.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "    ax.plot(ls.cpu(), geo_mean_emit.detach().cpu()*1.e-6, label='GP mean')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1825a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tuned = optimizer.generator.algorithm_results['x_stars'][sid:sid+1, :]\n",
    "X_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import get_meas_scan_inputs_from_tuning_configs\n",
    "x_meas = torch.linspace(-3,3,100)\n",
    "x_tuning = X_tuned\n",
    "# x_tuning = torch.tensor([[ 0., 0.]])\n",
    "# x_tuning = torch.tensor([[ 0., 0.]])\n",
    "x_meas_scan = get_meas_scan_inputs_from_tuning_configs(meas_dim=meas_dim, x_tuning=x_tuning, x_meas=x_meas)\n",
    "\n",
    "bss_posterior = beam_size_model_x.posterior(x_meas_scan)\n",
    "bss_mean = bss_posterior.mean.flatten().detach()\n",
    "bss_var = bss_posterior.variance.flatten().detach()\n",
    "plt.plot(x_meas, bss_mean.detach())\n",
    "plt.fill_between(x_meas, (bss_mean-bss_var.sqrt()), (bss_mean+bss_var.sqrt()), color='C0', alpha=0.3)\n",
    "plt.title('Mean-Square Beam Size GP Model Output')\n",
    "plt.xlabel('Measurement Quad Focusing Strength ($[k]=m^{-2}$)')\n",
    "plt.ylabel('Mean-Square Beam Size (mm)')\n",
    "print(\"x_tuning:\", x_tuning)\n",
    "# textstr = r\"$x_tuning=%d$\" % (x_tuning,)\n",
    "\n",
    "# # these are matplotlib.patch.Patch properties\n",
    "# props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "# # place a text box in upper left in axes coords\n",
    "# plt.text(\n",
    "#     0.95,\n",
    "#     0.05,\n",
    "#     textstr,\n",
    "#     transform=ax.transAxes,\n",
    "#     fontsize=14,\n",
    "#     verticalalignment=\"bottom\",\n",
    "#     horizontalalignment=\"right\",\n",
    "#     bbox=props,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import get_valid_geo_mean_emittance_samples_thick_quad\n",
    "\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "    \n",
    "    emit_mean, emit_lower, emit_upper = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "    for i in range(len(X_tuning_scan)):\n",
    "        emit_valid, svr = get_valid_geo_mean_emittance_samples_thick_quad(\n",
    "            model=bax_model,\n",
    "            scale_factor=optimizer.generator.algorithm.scale_factor,\n",
    "            q_len=optimizer.generator.algorithm.q_len,\n",
    "            distance=optimizer.generator.algorithm.distance,\n",
    "            x_tuning=X_tuning_scan[i:i+1],\n",
    "            domain=optimizer.generator.vocs.bounds.T,\n",
    "            meas_dim=meas_dim,\n",
    "            n_samples=10000,\n",
    "            n_steps_quad_scan=10,\n",
    "            visualize=False,\n",
    "        )\n",
    "        mean = emit_valid.mean()\n",
    "        lower = torch.quantile(emit_valid, q=0.025)\n",
    "        upper = torch.quantile(emit_valid, q=0.975)\n",
    "        emit_mean = torch.cat((emit_mean, torch.tensor([mean])))\n",
    "        emit_lower = torch.cat((emit_lower, torch.tensor([lower])))\n",
    "        emit_upper = torch.cat((emit_upper, torch.tensor([upper])))\n",
    "\n",
    "#     plt.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    plt.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "    plt.plot(ls, emit_mean*1.e-6, label='Valid Sampling Model')\n",
    "    plt.fill_between(ls, emit_lower*1.e-6, emit_upper*1.e-6, alpha=0.3)\n",
    "    plt.xlabel('tuning param ' + str(scan_dim))\n",
    "    plt.ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "#     plt.ylim(0,1.81e-7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = bax_model.models\n",
    "bss_x = bss_model_x.outcome_transform.untransform(bss_model_x.train_targets)[0]\n",
    "bss_y = bss_model_y.outcome_transform.untransform(bss_model_y.train_targets)[0]\n",
    "bss = torch.sqrt(bss_x * bss_y)\n",
    "x_smallest_observed_beamsize = bss_model_x._original_train_inputs[torch.argmin(bss)].reshape(1,-1)\n",
    "\n",
    "tuning_dims = list(range(vocs.bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims = torch.tensor(tuning_dims)\n",
    "x_tuning_best = torch.index_select(x_smallest_observed_beamsize, dim=1, index=tuning_dims)\n",
    "x_tuning_best\n",
    "x_tuning_init = x_tuning_best.repeat(n_samples,1).flatten()\n",
    "x_tuning_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = model.models\n",
    "bss_x = bss_model_x.outcome_transform.untransform(bss_model_x.train_targets)[0]\n",
    "bss_y = bss_model_y.outcome_transform.untransform(bss_model_y.train_targets)[0]\n",
    "bss = torch.sqrt(bss_x * bss_y)\n",
    "x_smallest_observed_beamsize = bss_model_x._original_train_inputs[torch.argmin(bss)].reshape(1,-1)\n",
    "\n",
    "tuning_dims = list(range(bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims = torch.tensor(tuning_dims)\n",
    "x_tuning_best = torch.index_select(x_smallest_observed_beamsize, dim=1, index=tuning_dims)\n",
    "x_tuning_init = x_tuning_best.repeat(n_samples,1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68750b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_dims = list(range(vocs.bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = model.models\n",
    "bss_model_x.input_transform.untransform(bss_model_x.train_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a83e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.generator.algorithm_results['x_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x._original_train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x._original_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f129fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26383f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42400b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "9.033454852412253e-09 * (1+ls.abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import post_mean_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emits_sq = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_y,\n",
    "        scale_factor=-1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "\n",
    "    ax.plot(ls.cpu(), emits_sq.detach().cpu().sqrt()*1.e-6, label='Sample ' + str(sid))\n",
    "    ax.axvline(X_tuned[0,scan_dim].cpu(), c='r', label='Sample optimization result')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('\"$\\epsilon$\"')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import compute_emit_bmag_thick_quad\n",
    "k = torch.tensor([ 40., -10., -60.])\n",
    "y_batch = torch.tensor([[1777.4973,  680.4423, 8194.3948]])\n",
    "compute_emit_bmag_thick_quad(k, y_batch, q_len, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.generator.algorithm_results['x_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_model_cross_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {'x0':[-3.0, 1.0], 'x1': [-40.0, 40.0], 'x2': 1., 'x3': 0.}\n",
    "plot_model_cross_section(beam_size_model, vocs, scan_dict, nx=50, ny=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import (propagate_sig, \n",
    "                            build_quad_rmat, fit_gp_quad_scan, \n",
    "                            plot_valid_thick_quad_fits\n",
    "                          )\n",
    "\n",
    "def compute_emit_bmag_thick_quad(k, y_batch, q_len, rmat_quad_to_screen, beta0=1., alpha0=0.):\n",
    "    \"\"\"\n",
    "    A function that computes the emittance(s) corresponding to a set of quadrupole measurement scans\n",
    "    using a thick quad model.\n",
    "\n",
    "    Parameters:\n",
    "        k: 1d torch tensor of shape (n_steps_quad_scan,)\n",
    "            representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "            used in the emittance scan\n",
    "\n",
    "        y_batch: 2d torch tensor of shape (n_scans x n_steps_quad_scan),\n",
    "                where each row represents the mean-square beamsize outputs in [m^2] of an emittance scan\n",
    "                with inputs given by k\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "         \n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "\n",
    "        beta0: the design beta twiss parameter at the screen\n",
    "        \n",
    "        alpha0: the design alpha twiss parameter at the screen\n",
    "        \n",
    "    Returns:\n",
    "        emit: shape (n_scans x 1) containing the geometric emittance fit results for each scan\n",
    "        bmag_min: (n_scans x 1) containing the bmag corresponding to the optimal point for each scan\n",
    "        sig: shape (n_scans x 3 x 1) containing column vectors of [sig11, sig12, sig22]\n",
    "        is_valid: 1d tensor identifying physical validity of the emittance fit results\n",
    "        \n",
    "    SOURCE PAPER: http://www-library.desy.de/preparch/desy/thesis/desy-thesis-05-014.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # construct the A matrix from eq. (3.2) & (3.3) of source paper\n",
    "    quad_rmats = build_quad_rmat(k, q_len) # result shape (len(k) x 2 x 2)\n",
    "    total_rmats = rmat_quad_to_screen.reshape(1,2,2) @ quad_rmats # result shape (len(k) x 2 x 2)\n",
    "    \n",
    "    amat = torch.tensor([]) # prepare the A matrix\n",
    "    for rmat in total_rmats:\n",
    "        r11, r12 = rmat[0,0], rmat[0,1]\n",
    "        amat = torch.cat((amat, torch.tensor([[r11**2, 2.*r11*r12, r12**2]])), dim=0)\n",
    "    # amat result shape (len(k) x 3)\n",
    "    \n",
    "    # get sigma matrix elements just before measurement quad from pseudo-inverse\n",
    "    sig = amat.pinverse().unsqueeze(0) @ y_batch.unsqueeze(-1) # shapes (1 x 3 x len(k)) @ (n_scans x len(k) x 1)\n",
    "    # result shape (n_scans x 3 x 1) containing column vectors of [sig11, sig12, sig22]\n",
    "    \n",
    "    # compute emit\n",
    "    emit = torch.sqrt(sig[:,0,0]*sig[:,2,0] - sig[:,1,0]**2).reshape(-1,1) # result shape (n_scans x 1)\n",
    "\n",
    "    # check sigma matrix and emit for physical validity\n",
    "    is_valid = torch.logical_and(sig[:,0,0] > 0, sig[:,2,0] > 0) # result 1d tensor\n",
    "    is_valid = torch.logical_and(is_valid, ~torch.isnan(emit.flatten())) # result 1d tensor\n",
    "    \n",
    "    # propagate beam parameters to screen\n",
    "    twiss_at_screen = propagate_sig(sig, emit, total_rmats)[1]\n",
    "    # result shape (n_scans x len(k) x 3 x 1)\n",
    "    \n",
    "    # get design gamma0 from design beta0, alpha0\n",
    "    gamma0 = (1 + alpha0**2) / beta0\n",
    "    \n",
    "    # compute bmag\n",
    "    bmag = 0.5 * (twiss_at_screen[:,:,0,0] * gamma0\n",
    "                - 2 * twiss_at_screen[:,:,1,0] * alpha0\n",
    "                + twiss_at_screen[:,:,2,0] * beta0\n",
    "               )\n",
    "    # result shape (n_scans, n_steps_quad_scan)\n",
    "    \n",
    "    # select minimum bmag from quad scan\n",
    "    bmag_min, bmag_min_id = torch.min(bmag, dim=1, keepdim=True) # result shape (n_scans, 1) \n",
    "    \n",
    "    return emit, bmag_min, sig, is_valid\n",
    "\n",
    "def get_valid_emit_bmag_samples_from_quad_scan(\n",
    "    k,\n",
    "    y,\n",
    "    q_len,\n",
    "    rmat_quad_to_screen,\n",
    "    beta0=1.,\n",
    "    alpha0=0.,\n",
    "    n_samples=10000,\n",
    "    n_steps_quad_scan=10,\n",
    "    covar_module=None,\n",
    "    visualize=False,\n",
    "    tkwargs=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    A function that produces a distribution of possible (physically valid) emittance values corresponding\n",
    "    to a single quadrupole measurement scan. Data is first modeled by a SingleTaskGP, virtual measurement\n",
    "    scan samples are then drawn from the model posterior, the samples are modeled by thick-quad transport\n",
    "    to obtain fits to the beam parameters, and physically invalid results are discarded.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        k: 1d numpy array of shape (n_steps_quad_scan,)\n",
    "        representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "        used in the emittance scan\n",
    "\n",
    "        y: 1d numpy array of shape (n_steps_quad_scan, )\n",
    "            representing the root-mean-square beam size measurements in [m] of an emittance scan\n",
    "            with inputs given by k\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "\n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "\n",
    "        beta0: the design beta twiss parameter at the screen\n",
    "        \n",
    "        alpha0: the design alpha twiss parameter at the screen\n",
    "        \n",
    "        n_samples: the number of virtual measurement scan samples to evaluate for our \"Bayesian\" estimate\n",
    "\n",
    "        n_steps_quad_scan: the number of steps in our virtual measurement scans\n",
    "\n",
    "        covar_module: the covariance module to be used in fitting of the SingleTaskGP \n",
    "                    (modeling the function y**2 vs. k)\n",
    "                    If None, uses ScaleKernel(MaternKernel()).\n",
    "\n",
    "        visualize: boolean. Set to True to plot the parabolic fitting results.\n",
    "\n",
    "        tkwargs: dict containing the tensor device and dtype\n",
    "\n",
    "    Returns:\n",
    "        emits_valid: a tensor of physically valid emittance results from sampled measurement scans.\n",
    "\n",
    "        bmag_valid: (n_valid_scans x 1) containing the bmag corresponding to the optimal point \n",
    "                        from each physically valid fit.\n",
    "\n",
    "        sig_valid: tensor, shape (n_valid_scans x 3 x 1), containing the computed \n",
    "                        sig11, sig12, sig22 corresponding to each physically valid\n",
    "                        fit.\n",
    "\n",
    "        sample_validity_rate: a float between 0 and 1 that describes the rate at which the samples\n",
    "                        were physically valid/retained.\n",
    "    \"\"\"\n",
    "    if tkwargs is None:\n",
    "        tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "    k = torch.tensor(k, **tkwargs)\n",
    "    y = torch.tensor(y, **tkwargs)\n",
    "\n",
    "    k_virtual, bss = fit_gp_quad_scan(\n",
    "        k=k,\n",
    "        y=y,\n",
    "        n_samples=n_samples,\n",
    "        n_steps_quad_scan=n_steps_quad_scan,\n",
    "        covar_module=covar_module,\n",
    "        tkwargs=tkwargs\n",
    "    )\n",
    "    \n",
    "    (emit, bmag, sig, is_valid) = compute_emit_bmag_thick_quad(k=k_virtual, \n",
    "                                                              y_batch=bss, \n",
    "                                                              q_len=q_len, \n",
    "                                                              rmat_quad_to_screen=rmat_quad_to_screen, \n",
    "                                                              beta0=beta0, \n",
    "                                                              alpha0=alpha0)\n",
    "\n",
    "    sample_validity_rate = (torch.sum(is_valid) / is_valid.shape[0]).reshape(1)\n",
    "\n",
    "    # filter on physical validity\n",
    "    cut_ids = torch.tensor(range(emit.shape[0]))[is_valid]\n",
    "    emit_valid = torch.index_select(emit, dim=0, index=cut_ids)\n",
    "    bmag_valid = torch.index_select(bmag, dim=0, index=cut_ids)\n",
    "    sig_valid = torch.index_select(sig, dim=0, index=cut_ids)\n",
    "\n",
    "    if visualize:\n",
    "        plot_valid_thick_quad_fits(k=k, \n",
    "                                   y=y, \n",
    "                                   q_len=q_len, \n",
    "                                   distance=distance,\n",
    "                                   emit=emit_valid, \n",
    "                                   bmag=bmag_valid,\n",
    "                                   sig=sig_valid, \n",
    "                                  )\n",
    "    return emit_valid, bmag_valid, sig_valid, sample_validity_rate\n",
    "\n",
    "def plot_valid_thick_quad_fits(k, y, q_len, rmat_quad_to_screen, emit, bmag, sig, ci=0.95, tkwargs=None):\n",
    "    \"\"\"\n",
    "    A function to plot the physically valid fit results\n",
    "    produced by get_valid_emit_bmag_samples_from_quad_scan().\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        k: 1d numpy array of shape (n_steps_quad_scan,)\n",
    "        representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "        used in the emittance scan\n",
    "\n",
    "        y: 1d numpy array of shape (n_steps_quad_scan, )\n",
    "            representing the root-mean-square beam size measurements in [m] of an emittance scan\n",
    "            with inputs given by k\n",
    "\n",
    "        sig: tensor, shape (n_scans x 3 x 1), containing the computed sig11, sig12, sig22\n",
    "                corresponding to each measurement scan\n",
    "                \n",
    "        emit: shape (n_scans x 1) containing the geometric emittance fit results for each scan\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "\n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "                \n",
    "        ci: \"Confidence interval\" for plotting upper/lower quantiles.\n",
    "\n",
    "        tkwargs: dict containing the tensor device and dtype\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if tkwargs is None:\n",
    "        tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "    k_fit = torch.linspace(k.min(), k.max(), 10, **tkwargs)\n",
    "    quad_rmats = build_quad_rmat(k_fit, q_len) # result shape (len(k_fit) x 2 x 2)\n",
    "    total_rmats = rmat_quad_to_screen.reshape(1,2,2) @ quad_rmats # result shape (len(k_fit) x 2 x 2)\n",
    "    sig_final = propagate_sig(sig, emit, total_rmats)[0] # result shape len(sig) x len(k_fit) x 3 x 1\n",
    "    bss_fit = sig_final[:,:,0,0]\n",
    "\n",
    "    upper_quant = torch.quantile(bss_fit.sqrt(), q=0.5 + ci / 2.0, dim=0)\n",
    "    lower_quant = torch.quantile(bss_fit.sqrt(), q=0.5 - ci / 2.0, dim=0)\n",
    "    \n",
    "    fig, axs = plt.subplots(3)\n",
    "    fig.set_size_inches(5,9)\n",
    "    \n",
    "    ax=axs[0]\n",
    "    fit = ax.fill_between(\n",
    "        k_fit.detach().numpy(),\n",
    "        lower_quant*1.e6,\n",
    "        upper_quant*1.e6,\n",
    "        alpha=0.3,\n",
    "        label='\"Bayesian\" Thick-Quad Model',\n",
    "        zorder=1,\n",
    "    )\n",
    "    \n",
    "    obs = ax.scatter(\n",
    "        k, y*1.e6, marker=\"x\", s=120, c=\"orange\", label=\"Measurements\", zorder=2\n",
    "    )\n",
    "    ax.set_title(\"Beam Size at Screen\")\n",
    "    ax.set_xlabel(r\"Measurement Quad Geometric Focusing Strength ($[k]=m^{-2}$)\")\n",
    "    ax.set_ylabel(r\"r.m.s. Beam Size ($[\\sigma]=\\mu m$)\")\n",
    "    ax.legend(handles=[obs, fit])\n",
    "    \n",
    "    ax=axs[1]\n",
    "    ax.hist(emit.flatten(), density=True)\n",
    "    ax.set_title('Geometric Emittance Distribution')\n",
    "    ax.set_xlabel(r'Geometric Emittance ($[\\epsilon]=m*rad$)')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    \n",
    "    ax=axs[2]\n",
    "    ax.hist(bmag.flatten(), range=(1,5), bins=20, density=True)\n",
    "    ax.set_title(r'$\\beta_{mag}$ Distribution')\n",
    "    ax.set_xlabel(r'$\\beta_{mag}$ at Screen')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
