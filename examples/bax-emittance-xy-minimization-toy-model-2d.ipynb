{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ac8fe9",
   "metadata": {},
   "source": [
    "# Emittance minimization using Xopt with BAXGenerator running algorithm ScipyMinimizeEmittance\n",
    "In this notebook we demonstrate the use of Xopt to perform Bayesian Algorithm Execution (BAX) as a means of minimizing the emittance described by a simple optical beam size model. BAX is a generalization of Bayesian Optimization that seeks to acquire observations that provide our model with maximal information about our property of interest. In this example, our property of interest is the minimal emittance and its location in tuning-parameter-space. See https://arxiv.org/pdf/2209.04587.pdf for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2666c7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2005f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ObjLoader.__init_subclass__() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Xopt\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VOCS\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesian\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbax_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaxGenerator\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _version\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Xopt\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\base.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _version\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XoptError\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluator, validate_outputs\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_generator\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\evaluator.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, root_validator\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XoptError\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NormalExecutor, XoptBaseModel\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_function, get_function_defaults, safe_call\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\pydantic.py:210\u001b[0m\n\u001b[0;32m    205\u001b[0m         fn_args, fn_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mObjLoader\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m     GenericModel,\n\u001b[0;32m    212\u001b[0m     Generic[ObjType],\n\u001b[0;32m    213\u001b[0m     arbitrary_types_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    214\u001b[0m     json_dumps\u001b[38;5;241m=\u001b[39morjson_dumps,\n\u001b[0;32m    215\u001b[0m ):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mobject\u001b[39m: Optional[ObjType]\n\u001b[0;32m    217\u001b[0m     loader: CallableModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydantic\\_internal\\_model_construction.py:123\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_wrapper\u001b[38;5;241m.\u001b[39mfrozen:\n\u001b[0;32m    121\u001b[0m     set_default_hash_func(namespace, bases)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[BaseModel] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(mcs, cls_name, bases, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_custom_init__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_base_init__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xopt-dev\\lib\\abc.py:106\u001b[0m, in \u001b[0;36mABCMeta.__new__\u001b[1;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(mcls, name, bases, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(mcls, name, bases, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     _abc_init(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xopt-dev\\lib\\typing.py:1008\u001b[0m, in \u001b[0;36mGeneric.__init_subclass__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init_subclass__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__init_subclass__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1009\u001b[0m     tvars \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__orig_bases__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ObjLoader.__init_subclass__() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Dylan\\\\SLAC') #parent directory containing emitopt module\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "\n",
    "from emitopt.beam_dynamics import compute_emit_bmag\n",
    "from emitopt.sampling import draw_product_kernel_post_paths\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55e5b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydantic\n",
    "pydantic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36d6abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_key = None\n",
    "y_key = None\n",
    "[key for key in [x_key, y_key] if key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "904e49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "if not (x_key and y_key):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d378d",
   "metadata": {},
   "source": [
    "# Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "# if False:\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    use_cuda = True\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f6014",
   "metadata": {},
   "source": [
    "# Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9323010",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2 #number of input dimensions\n",
    "noise = False #whether to add noise to the ground-truth beam size function outputs\n",
    "meas_dim = 1 #input dimension for measurement parameter\n",
    "n_obs_init = 5 #number of random initial observations for GP model\n",
    "n_samples = 10 #number of posterior samples for BAX\n",
    "n_iter = 10 #number of optimization steps for Xopt to take (after acquiring random initial data)\n",
    "rand_seed = 2\n",
    "\n",
    "#random seeds for reproducibility \n",
    "torch.manual_seed(rand_seed)\n",
    "np.random.seed(rand_seed) #only affects initial random observations through Xopt\n",
    "random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87785524",
   "metadata": {},
   "source": [
    "# Build test function from single-quadrupole optical beam size model \n",
    "Here we define a simple ground-truth beam size function for our optimization problem, where we attempt to find the location in tuning parameter space with minimal emittance. Note that the function \"test_func\" used to evaluate the ground-truth beam size function takes a dictionary as input and returns a dictionary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468de1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemittance.emittance_calc import EmitCalc\n",
    "from pyemittance.load_json_configs import load_configs\n",
    "from pyemittance.simulation import BeamSim\n",
    "\n",
    "CONFIG = load_configs('LCLS2_OTR0H04')\n",
    "CONFIG['beamline_info']\n",
    "\n",
    "q_len = CONFIG['beamline_info']['Lquad']\n",
    "rmat_x = torch.tensor(CONFIG['beamline_info']['rMatx']).reshape(2,2)\n",
    "rmat_y = torch.tensor(CONFIG['beamline_info']['rMaty']).reshape(2,2)\n",
    "rmats = {'x':rmat_x, 'y':rmat_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c052d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUNCH_PARAMS0 = {\n",
    "    'total_charge': 50e-12,\n",
    "    'norm_emit_x': 1e-6,\n",
    "    'norm_emit_y': 2e-6,\n",
    "    'beta_x': 10,\n",
    "    'alpha_x': -1,\n",
    "    'beta_y': 11,\n",
    "    'alpha_y': -2,\n",
    "    'energy': 80e6,\n",
    "    'species':'electron'\n",
    "}\n",
    "sim = BeamSim(bunch_params=BUNCH_PARAMS0, beamline_info=CONFIG['beamline_info'])\n",
    "\n",
    "\n",
    "# define variables functions\n",
    "var_names = ['x' + str(i) for i in range(ndim)]\n",
    "meas_param = var_names[meas_dim]\n",
    "\n",
    "def measure_beamsize(input_dict):\n",
    "    x_tuning = torch.tensor([])\n",
    "    for key in input_dict.keys():\n",
    "        if key is not meas_param:\n",
    "            x_tuning = torch.cat((x_tuning, torch.tensor([input_dict[key]])))\n",
    "    rms_beamsizes0 = np.array(sim.beam_size_meas(input_dict[meas_param]))\n",
    "    detuning_scale = 1. + x_tuning.abs().sum().cpu()\n",
    "    xrms, yrms = detuning_scale * rms_beamsizes0\n",
    "    return {'xrms_sq': float(xrms)**2.*1.e6,\n",
    "            'yrms_sq': float(yrms)**2.*1.e6} # mean-square beam sizes in mm squared\n",
    "\n",
    "def ground_truth_geometric_mean_emittance(emit_min, x_tuning):\n",
    "    detuning_scale = 1. + x_tuning.abs().sum(dim=1)\n",
    "    emit = emit_min * detuning_scale**2\n",
    "    return emit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e9fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.56516435, 0.01566167]),\n",
       " array([0.10047318, 0.29068046]),\n",
       " array([0.01594597, 1.41311281])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.array(sim.beam_size_meas(v))**2*1.e6 for v in np.linspace(-2,2,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73bcfe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # define test functions\n",
    "# var_names = ['x' + str(i) for i in range(ndim)]\n",
    "# meas_param = var_names[meas_dim]\n",
    "\n",
    "# beam_energy = 0.135\n",
    "# distance = torch.tensor(2.26).double()\n",
    "# q_len = torch.tensor(0.108).double()\n",
    "# s11 = torch.tensor(3e-6).double()\n",
    "# s12 = torch.tensor(1.5e-6).double()\n",
    "# s22 = torch.tensor(2e-6).double()\n",
    "# gt_min_emit = torch.sqrt(s11 * s22 - s12 ** 2)*1e6\n",
    "# print('Ground-Truth Minimum Emittance:', gt_min_emit.item())\n",
    "\n",
    "\n",
    "\n",
    "# def beam_size_squared(k, d, l, s11, s12, s22):\n",
    "#     return (\n",
    "#         (1.0 + k * d * l) ** 2 * s11 + 2.0 * (1.0 + d * l * k) * d * s12 + d ** 2 * s22\n",
    "#     )\n",
    "    \n",
    "# def toy_beam_size_squared_nd(x, meas_dim, noise=noise):\n",
    "    \n",
    "#     tuning_dims = list(range(x.shape[-1]))\n",
    "#     tuning_dims.remove(meas_dim)\n",
    "#     emit = torch.sqrt(s11 * s22 - s12 ** 2)\n",
    "#     bss = ((1 + torch.sum(x[:,tuning_dims]**2, dim=1) )* beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)).reshape(-1,1) \n",
    "# #     bss = ( (1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(x[:,tuning_dims]**2, dim=1))) ) ) * \n",
    "# #            beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)\n",
    "# #           ).reshape(-1,1) \n",
    "#     bss *= 1.e6\n",
    "#     if noise:\n",
    "#         bss *= (1 + 0.05*torch.rand_like(bss))      \n",
    "#     return bss\n",
    "\n",
    "# def toy_emit_nd(X_tuning):\n",
    "# #     return ( 1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(X_tuning**2, dim=1))) ) ) * gt_min_emit\n",
    "#     return (1 + torch.sum(X_tuning**2, dim=1) ) * gt_min_emit\n",
    "\n",
    "# def test_func(input_dict):\n",
    "#     x = torch.tensor(input_dict[meas_param]).reshape(-1,1)\n",
    "#     for key in input_dict.keys():\n",
    "#         if key is not meas_param:\n",
    "#             x = torch.cat((x, torch.tensor(input_dict[key]).reshape(-1,1)), dim=1)\n",
    "#     return {'x': float(toy_beam_size_squared_nd(x, 0).squeeze().cpu().numpy()),\n",
    "#             'y': float(toy_beam_size_squared_nd(x, 0).squeeze().cpu().numpy()),\n",
    "#            'emittance': float(toy_emit_nd(x[:,1:]).squeeze().cpu().numpy())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2c09a",
   "metadata": {},
   "source": [
    "# Construct vocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfbf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_names = ['x0', 'x1']\n",
      "meas_param = 'x1'\n",
      "domain =\n",
      " [[-2.  2.]\n",
      " [-3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "variables = {var_name: [-2,2] for var_name in var_names}\n",
    "variables[meas_param] = [-3,3] #overwrite bounds for measurement parameter to capture minimum of single-quadrupole optical model\n",
    "\n",
    "#construct vocs\n",
    "vocs = VOCS(\n",
    "    variables = variables,\n",
    "    observables = ['xrms_sq', 'yrms_sq']\n",
    ")\n",
    "\n",
    "print('variable_names =', vocs.variable_names)\n",
    "print('meas_param =', \"'\" + meas_param + \"'\")\n",
    "print('domain =\\n', vocs.bounds.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4651f47",
   "metadata": {},
   "source": [
    "# Prepare generator options.\n",
    "In this example, we use a specialty covariance module (Matern x Quadratic kernel) for our beam size model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02894212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import MaternKernel, PolynomialKernel, ScaleKernel\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "# prepare custom covariance module\n",
    "tuning_dims = list(range(vocs.n_variables))\n",
    "tuning_dims.remove(meas_dim)\n",
    "covar_module_x = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "\n",
    "scaled_covar_module_x = ScaleKernel(covar_module_x)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "covar_module_y = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "scaled_covar_module_y =  ScaleKernel(covar_module_y)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "\n",
    "# prepare options for Xopt generator\n",
    "covar_module_dict = {'xrms_sq': scaled_covar_module_x,\n",
    "                     'yrms_sq': scaled_covar_module_y}\n",
    "\n",
    "model_constructor = StandardModelConstructor(covar_modules=covar_module_dict, use_low_noise_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.numerical_optimizer import LBFGSOptimizer\n",
    "numerical_optimizer = LBFGSOptimizer(\n",
    "                                    n_raw_samples=20,\n",
    "                                    n_restarts=10,\n",
    "                                    max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd586df8",
   "metadata": {},
   "source": [
    "# Construct generator, evaluator, Xopt objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7623bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Algorithm\n",
    "from emitopt.beam_dynamics import get_quad_scale_factor\n",
    "scale_factor = get_quad_scale_factor(E=.08, q_len=q_len)\n",
    "# scale_factor = 1.\n",
    "algo_kwargs = {\n",
    "        'model_names': {'x':'xrms_sq', 'y':'yrms_sq'},\n",
    "        'scale_factor': scale_factor,\n",
    "        'q_len': q_len,\n",
    "        'rmats': rmats,\n",
    "        'n_samples': n_samples,\n",
    "        'meas_dim': meas_dim,\n",
    "        'n_steps_measurement_param': 11,\n",
    "        'n_steps_exe_paths':  11,\n",
    "#         'scipy_options': {'gtol':1.e-8},\n",
    "}\n",
    "algo = ScipyMinimizeEmittanceXY(**algo_kwargs)\n",
    "\n",
    "#construct BAX generator\n",
    "generator = BaxGenerator(vocs=vocs, \n",
    "                         model_constructor=model_constructor, \n",
    "                         numerical_optimizer=numerical_optimizer,\n",
    "                         algorithm=algo, \n",
    "                         use_cuda=use_cuda)\n",
    "\n",
    "#construct evaluator\n",
    "evaluator = Evaluator(function=measure_beamsize)\n",
    "\n",
    "#construct Xopt optimizer\n",
    "optimizer = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae84fc5",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3553f6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>xrms_sq</th>\n",
       "      <th>yrms_sq</th>\n",
       "      <th>xopt_runtime</th>\n",
       "      <th>xopt_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.256020</td>\n",
       "      <td>1.017991</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>1.185247</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.896295</td>\n",
       "      <td>1.772108</td>\n",
       "      <td>0.062580</td>\n",
       "      <td>10.401808</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198650</td>\n",
       "      <td>-0.715626</td>\n",
       "      <td>0.317929</td>\n",
       "      <td>0.142012</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.258710</td>\n",
       "      <td>1.202072</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>1.360661</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.318529</td>\n",
       "      <td>1.399036</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>1.707620</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1   xrms_sq    yrms_sq  xopt_runtime  xopt_error\n",
       "1  0.256020  1.017991  0.019058   1.185247      0.002987       False\n",
       "2  1.896295  1.772108  0.062580  10.401808      0.001570       False\n",
       "3 -0.198650 -0.715626  0.317929   0.142012      0.000460       False\n",
       "4  0.258710  1.202072  0.009921   1.360661      0.000430       False\n",
       "5  0.318529  1.399036  0.005928   1.707620      0.000421       False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call X.random_evaluate() to generate random initial points and evaluate on test_func\n",
    "optimizer.random_evaluate(n_obs_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(optimizer.data[vocs.variable_names].iloc[-2].to_numpy().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af84ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# beam_size_models = {}\n",
    "\n",
    "# #get initial emittance prediction at ground truth optimum\n",
    "# model = optimizer.generator.train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a54961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 / 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# call X.step() to generate a random initial point and evaluate on test_func\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#extract GP models\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mtrain_model()\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\base.py:225\u001b[0m, in \u001b[0;36mXopt.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# generate samples and submit to evaluator\u001b[39;00m\n\u001b[0;32m    224\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_generate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m candidates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 225\u001b[0m new_samples \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_generate\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# generator is done when it returns no new samples\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_samples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\generators\\bayesian\\bax_generator.py:33\u001b[0m, in \u001b[0;36mBaxGenerator.generate\u001b[1;34m(self, n_candidates)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_candidates: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:157\u001b[0m, in \u001b[0;36mBayesianGenerator.generate\u001b[1;34m(self, n_candidates)\u001b[0m\n\u001b[0;32m    154\u001b[0m bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_optimization_bounds()\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# get acquisition function\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m acq_funct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_acquisition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# get candidates\u001b[39;00m\n\u001b[0;32m    160\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumerical_optimizer\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m    161\u001b[0m     acq_funct, bounds, n_candidates\n\u001b[0;32m    162\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:217\u001b[0m, in \u001b[0;36mBayesianGenerator.get_acquisition\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# get base acquisition function\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_acquisition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m acq\u001b[38;5;241m.\u001b[39msampler\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\xopt\\xopt\\generators\\bayesian\\bax_generator.py:38\u001b[0m, in \u001b[0;36mBaxGenerator._get_acquisition\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_acquisition\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m     36\u001b[0m     bax_model_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocs\u001b[38;5;241m.\u001b[39moutput_names\u001b[38;5;241m.\u001b[39mindex(name)\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_names_ordered\u001b[49m\n\u001b[0;32m     39\u001b[0m     ]\n\u001b[0;32m     40\u001b[0m     bax_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msubset_output(bax_model_ids)\n\u001b[0;32m     41\u001b[0m     eig \u001b[38;5;241m=\u001b[39m ModelListExpectedInformationGain(\n\u001b[0;32m     42\u001b[0m         bax_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_optimization_bounds()\n\u001b[0;32m     43\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\dylan\\slac\\emitopt\\emitopt\\algorithms.py:66\u001b[0m, in \u001b[0;36mScipyMinimizeEmittanceXY.model_names_ordered\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_names_ordered\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:  \n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# get observable model names in the order they appear in the model (ModelList)\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "# plt.xlabel('Predicted Optimal Emittance')\n",
    "# plt.ylabel('Probability Density')\n",
    "# plt.show()\n",
    "# print('sample validity rate:', svr)\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "\n",
    "    print('Iteration:', i, '/', n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # call X.step() to generate a random initial point and evaluate on test_func\n",
    "    optimizer.step()    \n",
    "\n",
    "    \n",
    "    #extract GP models\n",
    "    model = optimizer.generator.train_model()\n",
    "    bax_model_ids = [optimizer.generator.vocs.output_names.index(name)\n",
    "                            for name in optimizer.generator.algorithm.model_names_ordered]\n",
    "    bax_model = model.subset_output(bax_model_ids)\n",
    "    beam_size_model_x = bax_model.models[0]\n",
    "    beam_size_model_y = bax_model.models[1]\n",
    "    \n",
    "    #extract and store algorithm results for this iteration\n",
    "#     results[i] = optimizer.generator.algorithm_results\n",
    "#     beam_size_models[i] = beam_size_model\n",
    "    \n",
    "    #get mean-predicted optimal tuning config and eval predicted emits at this location in tuning parameter space\n",
    "    algo = optimizer.generator.algorithm\n",
    "#     X_tuned, emits_at_target_valid, svr = algo.mean_output(beam_size_model,\n",
    "#                                                          torch.tensor(vocs.bounds),\n",
    "#                                                          num_restarts=10)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('This iteration took:', end-start, 'seconds.\\n')\n",
    "\n",
    "#     if i % 5 == 0:\n",
    "#         plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "#         plt.xlabel('Predicted Optimal Emittance')\n",
    "#         plt.ylabel('Probability Density')\n",
    "#         plt.show()\n",
    "#         print('sample validity rate:', svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d344f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15])\n",
      "tensor([[0.0191, 0.0626, 0.3179, 0.0099, 0.0059, 0.8512, 0.1836, 1.5173, 0.2695,\n",
      "         0.3044, 0.0216, 1.6211, 0.4517, 0.0375, 0.3388]])\n",
      "bss.shape= torch.Size([1, 15])\n",
      "tensor(5)\n",
      "torch.Size([15, 2])\n",
      "get_acquisition took 0.17255330085754395 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "end = time.time()\n",
    "print('get_acquisition took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf24e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf took 1.7292726039886475 seconds.\n"
     ]
    }
   ],
   "source": [
    "from botorch.optim.optimize import optimize_acqf\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    res = optimize_acqf(acq_function=acq,\n",
    "                        bounds=torch.tensor(vocs.bounds),\n",
    "                        q=1,\n",
    "                        num_restarts=10,\n",
    "                        raw_samples=20,\n",
    "                        options={'maxiter':50}\n",
    "                       )\n",
    "end = time.time()\n",
    "print('optimize_acqf took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3181749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "\n",
    "# last_acq = np.vstack(data_all[0].iloc[-1][list(vocs.variable_data([vocs.random_inputs()], '').keys())].values[:]).astype(float)\n",
    "# last_acq = torch.tensor(last_acq).reshape(1,-1)\n",
    "\n",
    "last_acq = res[0]\n",
    "# last_acq = torch.tensor(optimizer.data[vocs.variable_names].iloc[-1].to_numpy().reshape(1,-1))\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim)\n",
    "    \n",
    "fig.set_size_inches(3*(ndim), 3)\n",
    "\n",
    "for scan_dim in range(ndim):\n",
    "    X_scan = last_acq.repeat(100,1)\n",
    "#     ls = torch.linspace(*vocs.bounds.T[scan_dim],100)\n",
    "    ls = torch.linspace(last_acq[0,scan_dim]-1,last_acq[0,scan_dim]+1,100)\n",
    "\n",
    "    X_scan[:,scan_dim] = ls\n",
    "\n",
    "    acq_scan = torch.tensor([acq(X.reshape(1,-1)) for X in X_scan]).reshape(-1)\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "    ax.plot(ls.cpu(), acq_scan.detach().cpu())\n",
    "    ax.axvline(last_acq[0,scan_dim].cpu(), c='r', label='Acquisition Result')\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel('Input ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('Acquisition Function')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ffbf95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emitopt.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01memitopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_sample_optima_convergence_inputs\n\u001b[0;32m      2\u001b[0m plot_sample_optima_convergence_inputs(results, show_valid_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emitopt.utils'"
     ]
    }
   ],
   "source": [
    "from emitopt.utils import plot_sample_optima_convergence_inputs\n",
    "plot_sample_optima_convergence_inputs(results, show_valid_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c512cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_sample_optima_convergence_emits\n",
    "plot_sample_optima_convergence_emits(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_valid_emit_prediction_at_x_tuning\n",
    "\n",
    "x_tuned = torch.mean(results[n_iter]['x_stars_all'], dim=0, keepdim=True)\n",
    "print('x_tuned =', x_tuned)\n",
    "plot_valid_emit_prediction_at_x_tuning(beam_size_model_x, \n",
    "                                       x_tuned, \n",
    "                                       scale_factor = algo_kwargs['scale_factor'],\n",
    "                                       q_len = algo_kwargs['q_len'],\n",
    "                                       distance = algo_kwargs['distance'],\n",
    "                                       bounds = vocs.bounds,\n",
    "                                       meas_dim = algo_kwargs['meas_dim'],\n",
    "                                       n_samples = 10000,\n",
    "                                       n_steps_quad_scan = 10\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a01f5",
   "metadata": {},
   "source": [
    "# Plot some beam size surface samples from our current model and do a scan of the predicted emittance as a function of our single tuning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d25716",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ndim==2:\n",
    "    \n",
    "    device = torch.tensor(1).device\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, subplot_kw={\"projection\": \"3d\"})\n",
    "    fig.set_size_inches(15,10)\n",
    "\n",
    "    ax = axs[0]\n",
    "\n",
    "    for s in range(3):\n",
    "\n",
    "        # plot first 3 beam size surface samples\n",
    "        xlin, ylin = torch.arange(-3,1,0.05), torch.arange(-40,40, 1.)\n",
    "        X, Y = torch.meshgrid(xlin, ylin)\n",
    "        XY = torch.cat((X.reshape(-1,1), Y.reshape(-1,1)), dim=1)\n",
    "        print(XY.shape)\n",
    "        Z = optimizer.generator.algorithm_results['post_paths_cpu'](XY)[s].reshape(X.shape).detach()\n",
    "        cmap='viridis'\n",
    "        surf = ax.plot_surface(Y, X, Z, cmap=cmap,\n",
    "                               linewidth=0, antialiased=True, alpha=0.3, rasterized=True)\n",
    "\n",
    "        # add orange parabolic highlights\n",
    "        ax.plot(Y[0,:].numpy(), Z[0,:].numpy(), zs=X[0,0].item(), zdir='y', c='C1', lw=2, zorder=10)\n",
    "        ax.plot(Y[int(len(Z[0,:])/2),:].numpy(), Z[int(len(Z[0,:])/2),:].numpy(), zs=X[int(len(Z[0,:])/2),0].item(), zdir='y', c='C1', lw=2)\n",
    "        ax.plot(Y[-1,:].numpy(), Z[-1,:].numpy(), zs=X[-1,0].item(), zdir='y', c='C1', lw=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot initial observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[:n_obs_init]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[:n_obs_init]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[:n_obs_init]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C0', alpha=1, s=80, label='Random (Initial) Observations', zorder=15)\n",
    "\n",
    "    # plot bax observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[n_obs_init:]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[n_obs_init:]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[n_obs_init:]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C1', alpha=1, s=80, label='BAX Observations', zorder=15)\n",
    "\n",
    "    ax.set_title('Beam Size Surface Samples')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Measurement Parameter')\n",
    "    ax.set_zlabel('Beam Size Squared')\n",
    "\n",
    "    ax.set_ylim(-3, 1)\n",
    "    ax.set_zlim(0)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        torch.set_default_tensor_type(\"torch.cuda.DoubleTensor\")\n",
    "        \n",
    "   \n",
    "\n",
    "    # do a scan (along the tuning dimension) of our emittance predictions\n",
    "    emit_lowers = torch.tensor([])\n",
    "    emit_uppers = torch.tensor([])\n",
    "    emit_meds = torch.tensor([])\n",
    "    for tuning_param in xlin:\n",
    "        x_tuning = tuning_param.reshape(1,-1).to(device)\n",
    "        emits, svr = get_valid_emittance_samples(beam_size_model, \n",
    "                                                 scale_factor, \n",
    "                                                 0.108, \n",
    "                                                 2.26, \n",
    "                                                 x_tuning, \n",
    "                                                 vocs.bounds.T, \n",
    "                                                 meas_dim, \n",
    "                                                 n_samples=100000, \n",
    "                                                 n_steps_quad_scan=10)\n",
    "        emit_lower = torch.quantile(emits, q=0.025, dim=0)\n",
    "        emit_upper = torch.quantile(emits, q=0.975, dim=0)\n",
    "        emit_med = torch.quantile(emits, q=0.5, dim=0)\n",
    "\n",
    "        emit_lowers = torch.cat((emit_lowers, emit_lower))\n",
    "        emit_uppers = torch.cat((emit_uppers, emit_upper))\n",
    "        emit_meds = torch.cat((emit_meds, emit_med))\n",
    "\n",
    "    #get a few batches of n_samples pathwise sample optima\n",
    "    x_stars_all = torch.tensor([])\n",
    "    emit_stars_all = torch.tensor([])\n",
    "    for i in range(5):\n",
    "        algo = optimizer.generator.algorithm\n",
    "        results_dict = algo.get_execution_paths(beam_size_model, torch.tensor(vocs.bounds))[-1]\n",
    "        x_stars = results_dict['x_stars']\n",
    "        emit_stars = results_dict['emit_stars'].detach()\n",
    "        x_stars_all = torch.cat((x_stars_all, x_stars), dim=0)\n",
    "        emit_stars_all = torch.cat((emit_stars_all, emit_stars), dim=0)\n",
    "    \n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    ax = axs[1]\n",
    "    \n",
    "    # plot median emittance curve\n",
    "    medline, = ax.plot(emit_meds.cpu().numpy(), xlin.numpy(), zs=0, zdir='z', c='g', label='Median')\n",
    "    \n",
    "    opt_cross = ax.scatter(emit_stars_all.flatten().cpu(), x_stars_all.flatten().cpu(), zs=0, zdir='z', marker='x', s=40, c='m', alpha=0.5, label='Sample Optima')\n",
    "    \n",
    "    # plot emittance 95% confidence interval as a Poly3DCollection (ordering of vertices matters)\n",
    "    verts = (\n",
    "        [(emit_lowers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))] + \n",
    "        [(emit_uppers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))][::-1]\n",
    "    )\n",
    "    ax.add_collection3d(Poly3DCollection([verts],color='g', edgecolor='None', alpha=0.5)) # Add a polygon instead of fill_between\n",
    "\n",
    "    \n",
    "    ax.set_xlabel('Emittance')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_title('Emittance Measurement Samples')\n",
    "    \n",
    "    ax.set_xlim(0,25)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "\n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    orange_patch = mpatches.Patch(color='g', alpha=0.5, label='95% C.I.')\n",
    "    ax.legend(handles=[medline, orange_patch, opt_cross])\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    ax = axs[2]\n",
    "    bins = 10\n",
    "    freq, edges = torch.histogram(x_stars_all.flatten().cpu(), bins=bins, density=True)\n",
    "    for i in range(bins):\n",
    "        uverts = []\n",
    "        lverts = []\n",
    "        uverts += [(freq[i].item(), edges[i].item(), 0), (freq[i].item(), edges[i+1].item(), 0)]\n",
    "        lverts += [(0, edges[i+1].item(), 0), (0, edges[i].item(), 0)]\n",
    "        verts = uverts + lverts\n",
    "        ax.add_collection3d(Poly3DCollection([verts],color='m', edgecolor='k')) # Add a polygon instead of fill_between\n",
    "\n",
    "    ax.set_title('Distribution of Sample Optimal Tuning Parameters')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Frequency')\n",
    "    \n",
    "    ax.set_xlim(0,2)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "    \n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    \n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    \n",
    "    ax.dist = 12\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('beamsize-surfaces-with-emittance-1.svg', format='svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7907f",
   "metadata": {},
   "source": [
    "# Minimize sample emittance functions produced by current GP beam size model and inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select sample result\n",
    "\n",
    "sid = 5 #sample index to examine\n",
    "\n",
    "# X_tuned = X_sample_opt[sid].reshape(1,-1)\n",
    "X_tuned = optimizer.generator.algorithm_results['x_stars'][sid:sid+1, :]\n",
    "# X_tuned = torch.zeros(1,ndim-1)\n",
    "print('X_tuned =', X_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a841546",
   "metadata": {},
   "source": [
    "# Sample geometric mean of emittance x&y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23224da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import post_path_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emit_sq_x = post_path_emit_squared_thick_quad(optimizer.generator.algorithm_results['post_paths_cpu_xy'][0], \n",
    "                              1*optimizer.generator.algorithm.scale_factor, \n",
    "                              optimizer.generator.algorithm.q_len, \n",
    "                              optimizer.generator.algorithm.distance, \n",
    "                              X_tuning_scan.cpu(), meas_dim, X_meas.cpu(), samplewise=False)[0]\n",
    "    emit_sq_y = post_path_emit_squared_thick_quad(optimizer.generator.algorithm_results['post_paths_cpu_xy'][1], \n",
    "                              -1*optimizer.generator.algorithm.scale_factor, \n",
    "                              optimizer.generator.algorithm.q_len, \n",
    "                              optimizer.generator.algorithm.distance, \n",
    "                              X_tuning_scan.cpu(), meas_dim, X_meas.cpu(), samplewise=False)[0]\n",
    "    geo_mean_emit = torch.sqrt(emit_sq_x.abs().sqrt() * emit_sq_y.abs().sqrt())\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    ax.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "#     ax.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    ax.plot(ls.cpu(), geo_mean_emit[sid].detach().cpu()*1.e-6, label='Sample ' + str(sid))\n",
    "    ax.axvline(X_tuned[0,scan_dim].cpu(), c='r', label='Sample optimization result')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af9764",
   "metadata": {},
   "source": [
    "# Plot posterior mean model of geometric mean emttance x&y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b195f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import post_mean_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emit_sq_x = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_x,\n",
    "        scale_factor=1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]\n",
    "    emit_sq_y = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_y,\n",
    "        scale_factor=-1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]    \n",
    "    geo_mean_emit = torch.sqrt(emit_sq_x.abs().sqrt() * emit_sq_y.abs().sqrt())\n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "\n",
    "#     ax.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    ax.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "    ax.plot(ls.cpu(), geo_mean_emit.detach().cpu()*1.e-6, label='GP mean')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1825a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tuned = optimizer.generator.algorithm_results['x_stars'][sid:sid+1, :]\n",
    "X_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import get_meas_scan_inputs_from_tuning_configs\n",
    "x_meas = torch.linspace(-3,3,100)\n",
    "x_tuning = X_tuned\n",
    "# x_tuning = torch.tensor([[ 0., 0.]])\n",
    "# x_tuning = torch.tensor([[ 0., 0.]])\n",
    "x_meas_scan = get_meas_scan_inputs_from_tuning_configs(meas_dim=meas_dim, x_tuning=x_tuning, x_meas=x_meas)\n",
    "\n",
    "bss_posterior = beam_size_model_x.posterior(x_meas_scan)\n",
    "bss_mean = bss_posterior.mean.flatten().detach()\n",
    "bss_var = bss_posterior.variance.flatten().detach()\n",
    "plt.plot(x_meas, bss_mean.detach())\n",
    "plt.fill_between(x_meas, (bss_mean-bss_var.sqrt()), (bss_mean+bss_var.sqrt()), color='C0', alpha=0.3)\n",
    "plt.title('Mean-Square Beam Size GP Model Output')\n",
    "plt.xlabel('Measurement Quad Focusing Strength ($[k]=m^{-2}$)')\n",
    "plt.ylabel('Mean-Square Beam Size (mm)')\n",
    "print(\"x_tuning:\", x_tuning)\n",
    "# textstr = r\"$x_tuning=%d$\" % (x_tuning,)\n",
    "\n",
    "# # these are matplotlib.patch.Patch properties\n",
    "# props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "# # place a text box in upper left in axes coords\n",
    "# plt.text(\n",
    "#     0.95,\n",
    "#     0.05,\n",
    "#     textstr,\n",
    "#     transform=ax.transAxes,\n",
    "#     fontsize=14,\n",
    "#     verticalalignment=\"bottom\",\n",
    "#     horizontalalignment=\"right\",\n",
    "#     bbox=props,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import get_valid_geo_mean_emittance_samples_thick_quad\n",
    "\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "    \n",
    "    emit_mean, emit_lower, emit_upper = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "    for i in range(len(X_tuning_scan)):\n",
    "        emit_valid, svr = get_valid_geo_mean_emittance_samples_thick_quad(\n",
    "            model=bax_model,\n",
    "            scale_factor=optimizer.generator.algorithm.scale_factor,\n",
    "            q_len=optimizer.generator.algorithm.q_len,\n",
    "            distance=optimizer.generator.algorithm.distance,\n",
    "            x_tuning=X_tuning_scan[i:i+1],\n",
    "            domain=optimizer.generator.vocs.bounds.T,\n",
    "            meas_dim=meas_dim,\n",
    "            n_samples=10000,\n",
    "            n_steps_quad_scan=10,\n",
    "            visualize=False,\n",
    "        )\n",
    "        mean = emit_valid.mean()\n",
    "        lower = torch.quantile(emit_valid, q=0.025)\n",
    "        upper = torch.quantile(emit_valid, q=0.975)\n",
    "        emit_mean = torch.cat((emit_mean, torch.tensor([mean])))\n",
    "        emit_lower = torch.cat((emit_lower, torch.tensor([lower])))\n",
    "        emit_upper = torch.cat((emit_upper, torch.tensor([upper])))\n",
    "\n",
    "#     plt.plot(ls, 9.033454852412253e-09 * (1+ls.abs())**2, c='k', label='ground truth')\n",
    "    gt_emits = ground_truth_geometric_mean_emittance(emit_min=9.033454852412253e-09, x_tuning=X_tuning_scan)\n",
    "    plt.plot(ls, gt_emits, c='k', label='ground truth')\n",
    "    plt.plot(ls, emit_mean*1.e-6, label='Valid Sampling Model')\n",
    "    plt.fill_between(ls, emit_lower*1.e-6, emit_upper*1.e-6, alpha=0.3)\n",
    "    plt.xlabel('tuning param ' + str(scan_dim))\n",
    "    plt.ylabel('$\\sqrt{\\epsilon_x\\epsilon_y}$')\n",
    "#     plt.ylim(0,1.81e-7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = bax_model.models\n",
    "bss_x = bss_model_x.outcome_transform.untransform(bss_model_x.train_targets)[0]\n",
    "bss_y = bss_model_y.outcome_transform.untransform(bss_model_y.train_targets)[0]\n",
    "bss = torch.sqrt(bss_x * bss_y)\n",
    "x_smallest_observed_beamsize = bss_model_x._original_train_inputs[torch.argmin(bss)].reshape(1,-1)\n",
    "\n",
    "tuning_dims = list(range(vocs.bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims = torch.tensor(tuning_dims)\n",
    "x_tuning_best = torch.index_select(x_smallest_observed_beamsize, dim=1, index=tuning_dims)\n",
    "x_tuning_best\n",
    "x_tuning_init = x_tuning_best.repeat(n_samples,1).flatten()\n",
    "x_tuning_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = model.models\n",
    "bss_x = bss_model_x.outcome_transform.untransform(bss_model_x.train_targets)[0]\n",
    "bss_y = bss_model_y.outcome_transform.untransform(bss_model_y.train_targets)[0]\n",
    "bss = torch.sqrt(bss_x * bss_y)\n",
    "x_smallest_observed_beamsize = bss_model_x._original_train_inputs[torch.argmin(bss)].reshape(1,-1)\n",
    "\n",
    "tuning_dims = list(range(bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims = torch.tensor(tuning_dims)\n",
    "x_tuning_best = torch.index_select(x_smallest_observed_beamsize, dim=1, index=tuning_dims)\n",
    "x_tuning_init = x_tuning_best.repeat(n_samples,1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68750b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_dims = list(range(vocs.bounds.shape[1]))\n",
    "tuning_dims.remove(meas_dim)\n",
    "tuning_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x, bss_model_y = model.models\n",
    "bss_model_x.input_transform.untransform(bss_model_x.train_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a83e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.generator.algorithm_results['x_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x._original_train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bss_model_x._original_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f129fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26383f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42400b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "9.033454852412253e-09 * (1+ls.abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import post_mean_emit_squared_thick_quad\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-2,2,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-3,3,11)\n",
    "\n",
    "    emits_sq = post_mean_emit_squared_thick_quad(\n",
    "        model=beam_size_model_y,\n",
    "        scale_factor=-1*optimizer.generator.algorithm.scale_factor,\n",
    "        q_len=optimizer.generator.algorithm.q_len,\n",
    "        distance=optimizer.generator.algorithm.distance,\n",
    "        x_tuning=X_tuning_scan.cpu(),\n",
    "        meas_dim=meas_dim,\n",
    "        x_meas=X_meas.cpu(),\n",
    "    )[0]\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "#     ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "\n",
    "    ax.plot(ls.cpu(), emits_sq.detach().cpu().sqrt()*1.e-6, label='Sample ' + str(sid))\n",
    "    ax.axvline(X_tuned[0,scan_dim].cpu(), c='r', label='Sample optimization result')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('\"$\\epsilon$\"')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import compute_emit_bmag_thick_quad\n",
    "k = torch.tensor([ 40., -10., -60.])\n",
    "y_batch = torch.tensor([[1777.4973,  680.4423, 8194.3948]])\n",
    "compute_emit_bmag_thick_quad(k, y_batch, q_len, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.generator.algorithm_results['x_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_model_cross_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {'x0':[-3.0, 1.0], 'x1': [-40.0, 40.0], 'x2': 1., 'x3': 0.}\n",
    "plot_model_cross_section(beam_size_model, vocs, scan_dict, nx=50, ny=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import (propagate_sig, \n",
    "                            build_quad_rmat, fit_gp_quad_scan, \n",
    "                            plot_valid_thick_quad_fits\n",
    "                          )\n",
    "\n",
    "def compute_emit_bmag_thick_quad(k, y_batch, q_len, rmat_quad_to_screen, beta0=1., alpha0=0.):\n",
    "    \"\"\"\n",
    "    A function that computes the emittance(s) corresponding to a set of quadrupole measurement scans\n",
    "    using a thick quad model.\n",
    "\n",
    "    Parameters:\n",
    "        k: 1d torch tensor of shape (n_steps_quad_scan,)\n",
    "            representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "            used in the emittance scan\n",
    "\n",
    "        y_batch: 2d torch tensor of shape (n_scans x n_steps_quad_scan),\n",
    "                where each row represents the mean-square beamsize outputs in [m^2] of an emittance scan\n",
    "                with inputs given by k\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "         \n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "\n",
    "        beta0: the design beta twiss parameter at the screen\n",
    "        \n",
    "        alpha0: the design alpha twiss parameter at the screen\n",
    "        \n",
    "    Returns:\n",
    "        emit: shape (n_scans x 1) containing the geometric emittance fit results for each scan\n",
    "        bmag_min: (n_scans x 1) containing the bmag corresponding to the optimal point for each scan\n",
    "        sig: shape (n_scans x 3 x 1) containing column vectors of [sig11, sig12, sig22]\n",
    "        is_valid: 1d tensor identifying physical validity of the emittance fit results\n",
    "        \n",
    "    SOURCE PAPER: http://www-library.desy.de/preparch/desy/thesis/desy-thesis-05-014.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # construct the A matrix from eq. (3.2) & (3.3) of source paper\n",
    "    quad_rmats = build_quad_rmat(k, q_len) # result shape (len(k) x 2 x 2)\n",
    "    total_rmats = rmat_quad_to_screen.reshape(1,2,2) @ quad_rmats # result shape (len(k) x 2 x 2)\n",
    "    \n",
    "    amat = torch.tensor([]) # prepare the A matrix\n",
    "    for rmat in total_rmats:\n",
    "        r11, r12 = rmat[0,0], rmat[0,1]\n",
    "        amat = torch.cat((amat, torch.tensor([[r11**2, 2.*r11*r12, r12**2]])), dim=0)\n",
    "    # amat result shape (len(k) x 3)\n",
    "    \n",
    "    # get sigma matrix elements just before measurement quad from pseudo-inverse\n",
    "    sig = amat.pinverse().unsqueeze(0) @ y_batch.unsqueeze(-1) # shapes (1 x 3 x len(k)) @ (n_scans x len(k) x 1)\n",
    "    # result shape (n_scans x 3 x 1) containing column vectors of [sig11, sig12, sig22]\n",
    "    \n",
    "    # compute emit\n",
    "    emit = torch.sqrt(sig[:,0,0]*sig[:,2,0] - sig[:,1,0]**2).reshape(-1,1) # result shape (n_scans x 1)\n",
    "\n",
    "    # check sigma matrix and emit for physical validity\n",
    "    is_valid = torch.logical_and(sig[:,0,0] > 0, sig[:,2,0] > 0) # result 1d tensor\n",
    "    is_valid = torch.logical_and(is_valid, ~torch.isnan(emit.flatten())) # result 1d tensor\n",
    "    \n",
    "    # propagate beam parameters to screen\n",
    "    twiss_at_screen = propagate_sig(sig, emit, total_rmats)[1]\n",
    "    # result shape (n_scans x len(k) x 3 x 1)\n",
    "    \n",
    "    # get design gamma0 from design beta0, alpha0\n",
    "    gamma0 = (1 + alpha0**2) / beta0\n",
    "    \n",
    "    # compute bmag\n",
    "    bmag = 0.5 * (twiss_at_screen[:,:,0,0] * gamma0\n",
    "                - 2 * twiss_at_screen[:,:,1,0] * alpha0\n",
    "                + twiss_at_screen[:,:,2,0] * beta0\n",
    "               )\n",
    "    # result shape (n_scans, n_steps_quad_scan)\n",
    "    \n",
    "    # select minimum bmag from quad scan\n",
    "    bmag_min, bmag_min_id = torch.min(bmag, dim=1, keepdim=True) # result shape (n_scans, 1) \n",
    "    \n",
    "    return emit, bmag_min, sig, is_valid\n",
    "\n",
    "def get_valid_emit_bmag_samples_from_quad_scan(\n",
    "    k,\n",
    "    y,\n",
    "    q_len,\n",
    "    rmat_quad_to_screen,\n",
    "    beta0=1.,\n",
    "    alpha0=0.,\n",
    "    n_samples=10000,\n",
    "    n_steps_quad_scan=10,\n",
    "    covar_module=None,\n",
    "    visualize=False,\n",
    "    tkwargs=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    A function that produces a distribution of possible (physically valid) emittance values corresponding\n",
    "    to a single quadrupole measurement scan. Data is first modeled by a SingleTaskGP, virtual measurement\n",
    "    scan samples are then drawn from the model posterior, the samples are modeled by thick-quad transport\n",
    "    to obtain fits to the beam parameters, and physically invalid results are discarded.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        k: 1d numpy array of shape (n_steps_quad_scan,)\n",
    "        representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "        used in the emittance scan\n",
    "\n",
    "        y: 1d numpy array of shape (n_steps_quad_scan, )\n",
    "            representing the root-mean-square beam size measurements in [m] of an emittance scan\n",
    "            with inputs given by k\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "\n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "\n",
    "        beta0: the design beta twiss parameter at the screen\n",
    "        \n",
    "        alpha0: the design alpha twiss parameter at the screen\n",
    "        \n",
    "        n_samples: the number of virtual measurement scan samples to evaluate for our \"Bayesian\" estimate\n",
    "\n",
    "        n_steps_quad_scan: the number of steps in our virtual measurement scans\n",
    "\n",
    "        covar_module: the covariance module to be used in fitting of the SingleTaskGP \n",
    "                    (modeling the function y**2 vs. k)\n",
    "                    If None, uses ScaleKernel(MaternKernel()).\n",
    "\n",
    "        visualize: boolean. Set to True to plot the parabolic fitting results.\n",
    "\n",
    "        tkwargs: dict containing the tensor device and dtype\n",
    "\n",
    "    Returns:\n",
    "        emits_valid: a tensor of physically valid emittance results from sampled measurement scans.\n",
    "\n",
    "        bmag_valid: (n_valid_scans x 1) containing the bmag corresponding to the optimal point \n",
    "                        from each physically valid fit.\n",
    "\n",
    "        sig_valid: tensor, shape (n_valid_scans x 3 x 1), containing the computed \n",
    "                        sig11, sig12, sig22 corresponding to each physically valid\n",
    "                        fit.\n",
    "\n",
    "        sample_validity_rate: a float between 0 and 1 that describes the rate at which the samples\n",
    "                        were physically valid/retained.\n",
    "    \"\"\"\n",
    "    if tkwargs is None:\n",
    "        tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "    k = torch.tensor(k, **tkwargs)\n",
    "    y = torch.tensor(y, **tkwargs)\n",
    "\n",
    "    k_virtual, bss = fit_gp_quad_scan(\n",
    "        k=k,\n",
    "        y=y,\n",
    "        n_samples=n_samples,\n",
    "        n_steps_quad_scan=n_steps_quad_scan,\n",
    "        covar_module=covar_module,\n",
    "        tkwargs=tkwargs\n",
    "    )\n",
    "    \n",
    "    (emit, bmag, sig, is_valid) = compute_emit_bmag_thick_quad(k=k_virtual, \n",
    "                                                              y_batch=bss, \n",
    "                                                              q_len=q_len, \n",
    "                                                              rmat_quad_to_screen=rmat_quad_to_screen, \n",
    "                                                              beta0=beta0, \n",
    "                                                              alpha0=alpha0)\n",
    "\n",
    "    sample_validity_rate = (torch.sum(is_valid) / is_valid.shape[0]).reshape(1)\n",
    "\n",
    "    # filter on physical validity\n",
    "    cut_ids = torch.tensor(range(emit.shape[0]))[is_valid]\n",
    "    emit_valid = torch.index_select(emit, dim=0, index=cut_ids)\n",
    "    bmag_valid = torch.index_select(bmag, dim=0, index=cut_ids)\n",
    "    sig_valid = torch.index_select(sig, dim=0, index=cut_ids)\n",
    "\n",
    "    if visualize:\n",
    "        plot_valid_thick_quad_fits(k=k, \n",
    "                                   y=y, \n",
    "                                   q_len=q_len, \n",
    "                                   distance=distance,\n",
    "                                   emit=emit_valid, \n",
    "                                   bmag=bmag_valid,\n",
    "                                   sig=sig_valid, \n",
    "                                  )\n",
    "    return emit_valid, bmag_valid, sig_valid, sample_validity_rate\n",
    "\n",
    "def plot_valid_thick_quad_fits(k, y, q_len, rmat_quad_to_screen, emit, bmag, sig, ci=0.95, tkwargs=None):\n",
    "    \"\"\"\n",
    "    A function to plot the physically valid fit results\n",
    "    produced by get_valid_emit_bmag_samples_from_quad_scan().\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        k: 1d numpy array of shape (n_steps_quad_scan,)\n",
    "        representing the measurement quad geometric focusing strengths in [m^-2]\n",
    "        used in the emittance scan\n",
    "\n",
    "        y: 1d numpy array of shape (n_steps_quad_scan, )\n",
    "            representing the root-mean-square beam size measurements in [m] of an emittance scan\n",
    "            with inputs given by k\n",
    "\n",
    "        sig: tensor, shape (n_scans x 3 x 1), containing the computed sig11, sig12, sig22\n",
    "                corresponding to each measurement scan\n",
    "                \n",
    "        emit: shape (n_scans x 1) containing the geometric emittance fit results for each scan\n",
    "\n",
    "        q_len: float defining the (longitudinal) quadrupole length or \"thickness\" in [m]\n",
    "\n",
    "        rmat_quad_to_screen: the (fixed) 2x2 R matrix describing the transport from the end of the \n",
    "                measurement quad to the observation screen.\n",
    "                \n",
    "        ci: \"Confidence interval\" for plotting upper/lower quantiles.\n",
    "\n",
    "        tkwargs: dict containing the tensor device and dtype\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if tkwargs is None:\n",
    "        tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "    k_fit = torch.linspace(k.min(), k.max(), 10, **tkwargs)\n",
    "    quad_rmats = build_quad_rmat(k_fit, q_len) # result shape (len(k_fit) x 2 x 2)\n",
    "    total_rmats = rmat_quad_to_screen.reshape(1,2,2) @ quad_rmats # result shape (len(k_fit) x 2 x 2)\n",
    "    sig_final = propagate_sig(sig, emit, total_rmats)[0] # result shape len(sig) x len(k_fit) x 3 x 1\n",
    "    bss_fit = sig_final[:,:,0,0]\n",
    "\n",
    "    upper_quant = torch.quantile(bss_fit.sqrt(), q=0.5 + ci / 2.0, dim=0)\n",
    "    lower_quant = torch.quantile(bss_fit.sqrt(), q=0.5 - ci / 2.0, dim=0)\n",
    "    \n",
    "    fig, axs = plt.subplots(3)\n",
    "    fig.set_size_inches(5,9)\n",
    "    \n",
    "    ax=axs[0]\n",
    "    fit = ax.fill_between(\n",
    "        k_fit.detach().numpy(),\n",
    "        lower_quant*1.e6,\n",
    "        upper_quant*1.e6,\n",
    "        alpha=0.3,\n",
    "        label='\"Bayesian\" Thick-Quad Model',\n",
    "        zorder=1,\n",
    "    )\n",
    "    \n",
    "    obs = ax.scatter(\n",
    "        k, y*1.e6, marker=\"x\", s=120, c=\"orange\", label=\"Measurements\", zorder=2\n",
    "    )\n",
    "    ax.set_title(\"Beam Size at Screen\")\n",
    "    ax.set_xlabel(r\"Measurement Quad Geometric Focusing Strength ($[k]=m^{-2}$)\")\n",
    "    ax.set_ylabel(r\"r.m.s. Beam Size ($[\\sigma]=\\mu m$)\")\n",
    "    ax.legend(handles=[obs, fit])\n",
    "    \n",
    "    ax=axs[1]\n",
    "    ax.hist(emit.flatten(), density=True)\n",
    "    ax.set_title('Geometric Emittance Distribution')\n",
    "    ax.set_xlabel(r'Geometric Emittance ($[\\epsilon]=m*rad$)')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    \n",
    "    ax=axs[2]\n",
    "    ax.hist(bmag.flatten(), range=(1,5), bins=20, density=True)\n",
    "    ax.set_title(r'$\\beta_{mag}$ Distribution')\n",
    "    ax.set_xlabel(r'$\\beta_{mag}$ at Screen')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
